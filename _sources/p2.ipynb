{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6ee1c0bed7184768a4722eb3704dcc37","deepnote_cell_type":"text-cell-h1"},"source":"# Analisis Bisnis untuk Memprediksi Tren Penjualan Mobil","block_group":"3bd664cbb3e744179608599f7ff45b0f"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"1752c0a3bf214e56b456b7cc9364ea25","deepnote_cell_type":"text-cell-h2"},"source":"## 1.  Memahami Bisnis","block_group":"ff2126e4b9c948b0b7c3d1486de18249"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e76617583f9049f38329412c51279f3d","deepnote_cell_type":"text-cell-p"},"source":"Industri otomotif merupakan salah satu sektor yang sangat dinamis dan penuh tantangan. Dalam beberapa tahun terakhir, permintaan terhadap kendaraan terus berkembang seiring dengan pertumbuhan ekonomi dan perubahan gaya hidup masyarakat. Namun, cepatnya perubahan tren pasar membuat para pelaku industri otomotif perlu memiliki pemahaman yang lebih mendalam tentang pola penjualan dan preferensi konsumen. Oleh karena itu, prediksi penjualan mobil menjadi hal yang sangat penting untuk mengoptimalkan strategi bisnis dan meningkatkan daya saing perusahaan. Visi perusahaan kami adalah menjadi perusahaan terkemuka dalam industri otomotif yang mampu memanfaatkan teknologi analitik untuk mengambil keputusan bisnis yang cerdas, tepat waktu, dan berbasis data. Untuk mencapai visi tersebut, misi kami adalah mengembangkan dan memanfaatkan sistem prediksi berbasis data untuk meramalkan tren penjualan mobil secara lebih akurat, menyediakan solusi analitik yang dapat membantu pemangku kepentingan dalam pengambilan keputusan yang lebih efektif dan efisien, serta meningkatkan pemahaman pasar dan preferensi konsumen untuk mendukung pengembangan produk dan strategi pemasaran yang lebih tepat sasaran. Strategi bisnis yang kami terapkan fokus pada pemanfaatan teknologi untuk memahami tren pasar, preferensi konsumen. Dengan menggunakan analisis data yang mendalam, perusahaan kami dapat merencanakan produksi, distribusi, dan pemasaran dengan lebih efisien. ","block_group":"89153249e30c43dfa8a2b091e84e93cd"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4098334fb41b40ff8c839b186a4264cb","deepnote_cell_type":"text-cell-h3"},"source":"### 1.1. tujuan Analisis","block_group":"0e4397752fb940ffa391942dde5cca39"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3566a2338c9f48bfbbf4af0fd7d397df","deepnote_cell_type":"text-cell-bullet"},"source":"- Meningkatkan Akurasi Prediksi: Menggunakan algoritma machine learning untuk memprediksi penjualan mobil dengan lebih akurat.","block_group":"80ac8ebbb83a445ebfdaf6b8d60aa257"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e2ec8265348d47b4b91f81d76286a57a","deepnote_cell_type":"text-cell-bullet"},"source":"- Optimalkan Model: Mengembangkan model yang terus belajar dan beradaptasi dengan perubahan pasar.","block_group":"0702c4c09d0a4133a77b29bfc51ed106"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1f534fdd50a6460a923767a7ef0e86e4","deepnote_cell_type":"text-cell-bullet"},"source":"- Pengelolaan Inventaris: Membantu merencanakan stok dan produksi berdasarkan prediksi penjualan.","block_group":"9b62afbb5c3741e88ffb2d0ada8bc6f2"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a69e6e6f7eec47b0904cddde42eff64d","deepnote_cell_type":"text-cell-bullet"},"source":"- Dukung Keputusan Pemasaran: Menyusun strategi pemasaran yang tepat sasaran berdasarkan hasil prediksi.","block_group":"53a1c6ae39f24008887dcbf6c16f2d9c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7b6d5c3abc0c48efaebb5ea359496059","deepnote_cell_type":"text-cell-h3"},"source":"### 1.2. Permasalahan Analisis bisnis","block_group":"3c8d51b654254c78a7bdc1f99763ccf1"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7b342153807b4ccfaf1d773126ac5042","deepnote_cell_type":"text-cell-bullet"},"source":"- Melakukan analisis tren penjualan mobil menggunakan metode machine learning untuk memprediksi pola penjualan yang lebih akurat.","block_group":"555e127468fe46b6bdf36f1c013f717d"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9d63ecb62e71449dbdf4ca2196d04513","deepnote_cell_type":"text-cell-bullet"},"source":"- Mencari dan menentukan algoritma machine learning terbaik untuk memprediksi tren penjualan mobil dengan akurasi tinggi, serta mengoptimalkan model prediksi berdasarkan data yang tersedia.","block_group":"6c341969296a4ee9af16a53a80bc67e9"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"89c506bfcdbb4d4a9d84e201527a7301","deepnote_cell_type":"text-cell-h2"},"source":"## 2.  Memahami Data","block_group":"32d77191193b4879b0102fcc94e9b874"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d5439827c02048a296c6d0a04465a1da","deepnote_cell_type":"text-cell-h3"},"source":"### 2.1. Deskripsi Data","block_group":"09a9e523c79743399f5de46b35f2196c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"338db4d79adb439596881abe017eb072","deepnote_cell_type":"text-cell-p"},"source":"Dataset yang saya gunakan merupakan data time series bulanan yang mencatat penjualan mobil di Indonesia dari tahun 2010 hingga 2024. Data ini terdiri dari 178 record, dengan dua fitur utama, yaitu 'periode' yang menunjukkan bulan dan tahun, serta 'jumlah unit' yang mencatat jumlah mobil yang terjual setiap bulan. Dataset ini diperoleh dari situs web :","block_group":"bcc32c47d9fd409e9ae2216108c4e53c"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://triatmono.info/data-penjualan-tahun-2012/data-penjualan-mobil-2017/.\"","type":"link","ranges":[],"toCodePoint":75,"fromCodePoint":0}],"cell_id":"149ca3e67c6b4878b44b0e6e828b0317","deepnote_cell_type":"text-cell-p"},"source":"https://triatmono.info/data-penjualan-tahun-2012/data-penjualan-mobil-2017/","block_group":"e457b93f8995438b99e942a74c413409"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2b55517286dc4c898d285468501f0052","deepnote_cell_type":"text-cell-h3"},"source":"### 2.2. Tipe Data","block_group":"b2240b4f35fd45c4a830a930f52b98ac"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"97e0bc08c0104a2c97f04113e2f96427","deepnote_cell_type":"text-cell-p"},"source":"Dataset yang saya gunakan terdiri dari dua fitur, yaitu 'periode' dan 'jumlah unit.'","block_group":"d14a4248bec74beb8c9d80799c5717a4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"05cdddbc0f03426293042bb61e21f18e","deepnote_cell_type":"text-cell-bullet"},"source":"- Periode  :  Fitur ini memiliki tipe data string atau datetime yang mencatat bulan dan tahun penjualan mobil, misalnya 'Jan 2010' atau 'Feb 2024'. Tipe data ini digunakan untuk merepresentasikan waktu dalam format yang mudah dibaca dan diolah.","block_group":"eb2e8828e85442cf9286a0be0e24b81c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5f05a673b8e94696bacf387894d38f57","deepnote_cell_type":"text-cell-bullet"},"source":"- Jumlah Unit  : Fitur ini memiliki tipe data integer atau float yang mencatat jumlah mobil yang terjual pada setiap bulan. Tipe data ini berfungsi untuk menyimpan nilai numerik yang dapat digunakan dalam analisis kuantitatif, seperti prediksi atau perhitungan statistik.","block_group":"1dd9a02e3f904910b95cbde3d5aae14f"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c8f35c0b321f49d0ab2bc93733d552f9","deepnote_cell_type":"text-cell-h3"},"source":"### 2.3 Mengambil Data","block_group":"1368afd09c1d4eaf84ad3a7a048ac940"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d689117b214d42f2aaa3ad9a9a790a8c","deepnote_cell_type":"text-cell-p"},"source":"Untuk mengambil data penjualan mobil dari file CSV, kita dapat menggunakan library pandas. Pandas menyediakan fungsi read_csv() yang memungkinkan kita untuk membaca file CSV dan mengubahnya menjadi DataFrame, yang memudahkan kita untuk mengelola dan menganalisis data.","block_group":"cf870cdacf8f4b66bd785ea6769708b8"},{"cell_type":"code","metadata":{"source_hash":"9c213cbc","execution_start":1733555668590,"execution_millis":106,"execution_context_id":"abd1f878-46d8-4c87-ad5a-07b845a50fe5","cell_id":"62743f25a069425f8fc603c3d01d861e","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# Ganti '.csv' dengan path ke file CSV kamu\nfile_path = 'project2.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Menampilkan DataFrame\nprint(df)\n","block_group":"62743f25a069425f8fc603c3d01d861e","execution_count":2,"outputs":[{"name":"stdout","text":"    periode   unit\n0    10-Jan  52831\n1    10-Feb  55688\n2    10-Mar  65555\n3    10-Apr  65232\n4    10-May  60520\n..      ...    ...\n172  24-May  72245\n173  24-Jun  70289\n174  24-Jul  75608\n175  24-Aug  76808\n176  24-Sep  72337\n\n[177 rows x 2 columns]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/8c522557-bfd7-44c5-b5e5-b4bd9d521929","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"4ccaf5cd","execution_start":1733555704661,"execution_millis":272,"execution_context_id":"abd1f878-46d8-4c87-ad5a-07b845a50fe5","cell_id":"7eb306c67ab847bcb1695a9636aa211a","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# Ganti 'datamobil.csv' dengan path ke file CSV Anda\nfile_path = 'project2.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Memilih hanya kolom numerik\nnumerical_cols = df.select_dtypes(include=['float64', 'int64'])\n\n# Mencari nilai minimum dan maksimum untuk setiap kolom numerik\nmin_values = numerical_cols.min()\nmax_values = numerical_cols.max()\n\n# Menampilkan hasil\nprint(\"Nilai Minimum:\")\nprint(min_values)\nprint(\"\\nNilai Maksimum:\")\nprint(max_values)\n","block_group":"4c61dfde9f0f4fd88a14c5c08dd7243b","execution_count":4,"outputs":[{"name":"stdout","text":"Nilai Minimum:\nunit    17083\ndtype: int64\n\nNilai Maksimum:\nunit    115973\ndtype: int64\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/d793ca40-9aad-4f91-94d5-662762e561e6","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b19d0c7a41034cd9a1a239c39756c9b7","deepnote_cell_type":"text-cell-h2"},"source":"## 3. Processing Data","block_group":"dc5b61534c714138b81fa3d7abfcdd9f"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":366,"fromCodePoint":337},{"type":"marks","marks":{"bold":true},"toCodePoint":412,"fromCodePoint":395},{"type":"marks","marks":{"bold":true},"toCodePoint":433,"fromCodePoint":417}],"cell_id":"ff041830f384415a9e2a350bfa962e35","deepnote_cell_type":"text-cell-p"},"source":"Tujuan dari proses pengolahan data (data processing) adalah untuk menyiapkan data dalam bentuk yang dapat digunakan untuk analisis atau pembuatan model prediksi. Proses ini mencakup berbagai langkah yang bertujuan untuk memastikan data yang digunakan memiliki kualitas yang baik, relevan, dan siap digunakan. Pada data yang saya gunakan tidak terdapat missing value sehingga saya hanya melakukan Normalisasi data dan Sliding windows ","block_group":"2896c70765e24677af55087af07181dd"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d3faf84f46e4444fab1436c919a4827d","deepnote_cell_type":"text-cell-h3"},"source":"### 3.1 Normalisasi Data","block_group":"1b972af221b14f89a50f9d9bee5687a1"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"226c068f20a9460eb576383c8c964b77","deepnote_cell_type":"text-cell-p"},"source":"Untuk memastikan bahwa data yang digunakan dalam model prediksi berada dalam skala yang sama, kita dapat melakukan normalisasi menggunakan teknik MinMaxScaler. Teknik ini mengubah nilai-nilai dalam fitur menjadi rentang antara 0 dan 1, yang membantu meningkatkan kinerja model","block_group":"fac2dcea84254fac86ae2775d54f640a"},{"cell_type":"code","metadata":{"source_hash":"4c91883","execution_start":1733555857521,"execution_millis":330,"execution_context_id":"abd1f878-46d8-4c87-ad5a-07b845a50fe5","cell_id":"42588f6eb36a4b3a971692f7ae108c12","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Ganti 'datamobil.csv' dengan path ke file CSV kamu\nfile_path = 'project2.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Menampilkan DataFrame awal\nprint(\"Data Awal:\")\nprint(df)\n\n# Inisialisasi MinMaxScaler\nscaler = MinMaxScaler()\n\n# Melakukan normalisasi pada semua kolom numerik\ndf_normalized = df.copy()\n\n# Hanya kolom numerik yang akan dinormalisasi\nnumerical_cols = df_normalized.select_dtypes(include=['float64', 'int64']).columns\n\n# Normalisasi kolom numerik\ndf_normalized[numerical_cols] = scaler.fit_transform(df_normalized[numerical_cols])\n\n# Menampilkan DataFrame setelah normalisasi\nprint(\"Data Setelah Normalisasi:\")\nprint(df_normalized)\n\n# Menyimpan DataFrame yang telah dinormalisasi ke file CSV\noutput_path = 'datanormalisasi1.csv'  # Ganti dengan nama file output yang diinginkan\ndf_normalized.to_csv(output_path, index=False)\n\nprint(f\"Data telah disimpan ke {output_path}\")\n","block_group":"1ac50ec808444d098ed9e6a0f79ea1df","execution_count":6,"outputs":[{"name":"stdout","text":"Data Awal:\n    periode   unit\n0    10-Jan  52831\n1    10-Feb  55688\n2    10-Mar  65555\n3    10-Apr  65232\n4    10-May  60520\n..      ...    ...\n172  24-May  72245\n173  24-Jun  70289\n174  24-Jul  75608\n175  24-Aug  76808\n176  24-Sep  72337\n\n[177 rows x 2 columns]\nData Setelah Normalisasi:\n    periode      unit\n0    10-Jan  0.361493\n1    10-Feb  0.390383\n2    10-Mar  0.490161\n3    10-Apr  0.486895\n4    10-May  0.439246\n..      ...       ...\n172  24-May  0.557812\n173  24-Jun  0.538032\n174  24-Jul  0.591819\n175  24-Aug  0.603954\n176  24-Sep  0.558742\n\n[177 rows x 2 columns]\nData telah disimpan ke datanormalisasi1.csv\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/6bbb9e0c-f8db-4d46-a461-6c9288f59d7a","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"70cf3f13ad064940a76ac63368122196","deepnote_cell_type":"text-cell-h3"},"source":"### 3.2 sliding windows","block_group":"6d65dd2240ce485c8dd4d3455b7bb6b3"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8c824efbb98c4b0cb34c1dea992e8249","deepnote_cell_type":"text-cell-p"},"source":"Teknik ini digunakan untuk memecah data menjadi bagian-bagian yang lebih kecil (window) dengan ukuran tetap untuk analisis atau model prediksi, terutama dalam konteks data berurutan seperti sinyal, teks, atau time series. dalam code saya gunakan windows = 4","block_group":"5d68e6d7a7e54d6f9b3bee53fabdf0da"},{"cell_type":"code","metadata":{"source_hash":"77681729","execution_start":1733555922845,"execution_millis":388,"execution_context_id":"abd1f878-46d8-4c87-ad5a-07b845a50fe5","cell_id":"ba55bac10dd04e31902817d6052c3eb9","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# 1. Memuat data dari CSV\ndata = pd.read_csv('datanormalisasi1.csv')\n\n# 2. Membuat DataFrame untuk sliding window\ndf_slide = pd.DataFrame(data['unit'])\n\n# 3. Menambahkan kolom untuk sliding window\ndf_slide['xt-4'] = df_slide['unit'].shift(4)  # Nilai 4 langkah ke depan\ndf_slide['xt-3'] = df_slide['unit'].shift(3)  # Nilai 3 langkah ke depan\ndf_slide['xt-2'] = df_slide['unit'].shift(2)  # Nilai 2 langkah ke depan\ndf_slide['xt-1'] = df_slide['unit'].shift(1)  # Nilai 1 langkah ke depan\ndf_slide['xt'] = df_slide['unit']  # Nilai saat ini\n\n# 4. Menghapus baris yang memiliki NaN\ndf_slide = df_slide.dropna()\n\n# 5. Menghapus kolom 'unit' karena tidak diperlukan lagi\ndf_slide = df_slide.drop(columns=['unit'])\n\n# 6. Menyimpan data sliding ke file CSV\noutput_file = 'dataslide1.csv'\ndf_slide.to_csv(output_file, index=False)\n\n# 7. Menampilkan pesan sukses\nprint(f\"Data sliding telah disimpan ke file '{output_file}'.\")\n\n# Menampilkan DataFrame untuk verifikasi\nprint(df_slide)\n","block_group":"e55119eb7a9d4054ab5d0166f97bb797","execution_count":8,"outputs":[{"name":"stdout","text":"Data sliding telah disimpan ke file 'dataslide1.csv'.\n         xt-4      xt-3      xt-2      xt-1        xt\n4    0.361493  0.390383  0.490161  0.486895  0.439246\n5    0.390383  0.490161  0.486895  0.439246  0.539033\n6    0.490161  0.486895  0.439246  0.539033  0.556345\n7    0.486895  0.439246  0.539033  0.556345  0.482314\n8    0.439246  0.539033  0.556345  0.482314  0.324239\n..        ...       ...       ...       ...       ...\n172  0.620427  0.539357  0.658075  0.422763  0.557812\n173  0.539357  0.658075  0.422763  0.557812  0.538032\n174  0.658075  0.422763  0.557812  0.538032  0.591819\n175  0.422763  0.557812  0.538032  0.591819  0.603954\n176  0.557812  0.538032  0.591819  0.603954  0.558742\n\n[173 rows x 5 columns]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2da852b7-cf07-4c31-bb9f-577f2d5a3dd4","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3c42bcd9ed1e4560b0ece4d0e95932b0","deepnote_cell_type":"text-cell-h2"},"source":"## 4. Modelling","block_group":"a095b2f90aa04dc58beab27fb2cc2f05"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ea390da3d4d5463b83aba598a1cdaa59","deepnote_cell_type":"text-cell-p"},"source":"Pemilihan model yang tepat dalam prediksi penjualan mobil adalah kunci untuk menghasilkan hasil yang akurat, karena setiap model memiliki keunggulan dan kelemahan tergantung pada jenis data dan tujuan analisis. Pemilihan model yang salah bisa menyebabkan prediksi yang kurang tepat, yang pada gilirannya dapat merugikan proses pengambilan keputusan. sebelum melakakukan modelling bagi data menjadi data train dan tes","block_group":"3ce0eac1217c49679be2583c99770de5"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"ffe4947432044ff88af83675956f5980","deepnote_cell_type":"text-cell-p"},"source":"Membagi data train dan data tes :","block_group":"5a8b3129e7da4aca950c65f79c3f67a3"},{"cell_type":"code","metadata":{"cell_id":"8d56e4df753d492894573a3335e56b7c","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# 1. Memuat data dari CSV\ndata = pd.read_csv('datanormalisasi1.csv')\n\n# 2. Membuat DataFrame untuk sliding window\ndf_slide = pd.DataFrame(data['unit'])\n\n# 3. Menambahkan kolom untuk sliding window\ndf_slide['xt-4'] = df_slide['unit'].shift(4)  # Nilai 4 langkah ke depan\ndf_slide['xt-3'] = df_slide['unit'].shift(3)  # Nilai 3 langkah ke depan\ndf_slide['xt-2'] = df_slide['unit'].shift(2)  # Nilai 2 langkah ke depan\ndf_slide['xt-1'] = df_slide['unit'].shift(1)  # Nilai 1 langkah ke depan\ndf_slide['xt'] = df_slide['unit']  # Nilai saat ini\n\n# 4. Menghapus baris yang memiliki NaN\ndf_slide = df_slide.dropna()\n\n# 5. Menghapus kolom 'unit' karena tidak diperlukan lagi\ndf_slide = df_slide.drop(columns=['unit'])\n\n# 6. Memisahkan fitur dan target\nX = df_slide[['xt-4', 'xt-3', 'xt-2', 'xt-1']]  # Fitur (input)\ny = df_slide['xt']  # Target (output)\n\n# 7. Memisahkan data menjadi train dan test (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 8. Menggabungkan kembali fitur dan target untuk setiap set\ntrain_data = pd.concat([X_train, y_train], axis=1)\ntest_data = pd.concat([X_test, y_test], axis=1)\n\n# 9. Menyimpan data train dan test ke file CSV\ntrain_data.to_csv('train_data.csv', index=False)\ntest_data.to_csv('test_data.csv', index=False)\n\n# 10. Menampilkan pesan sukses\nprint(\"Data train telah disimpan ke file 'train_data.csv'.\")\nprint(\"Data test telah disimpan ke file 'test_data.csv'.\")\n","block_group":"9023c1f4d12749c284acc8bd008eb7c3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"426357d287d547d58bdaa3d10fbabbf6","deepnote_cell_type":"text-cell-h3"},"source":"### 4.1.  Metode ensemble bagging","block_group":"6347d6ace5de405f9a8d7e93be0825c9"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d40050a69ff646c88ff876a5e0d26d6b","deepnote_cell_type":"text-cell-p"},"source":"Metode ini digunakan untuk mengurangi variansi model dengan membangun banyak model pada subset acak dari data pelatihan, kemudian menggabungkan hasil prediksi dari model-model tersebut.","block_group":"816713feef2448769d21d8cfe0c1300d"},{"cell_type":"code","metadata":{"source_hash":"29159134","execution_start":1733630988601,"execution_millis":633,"execution_context_id":"dd8e3d77-baab-41ad-ab32-d8bd44221b1a","cell_id":"4c707522d3134e288e0fae21778e6c8a","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n\n# 1. Memuat data train dan test\ntrain_data = pd.read_csv('train_data.csv')\ntest_data = pd.read_csv('test_data.csv')\n\n# 2. Memisahkan fitur dan target\nX_train = train_data[['xt-4', 'xt-3', 'xt-2', 'xt-1']]\ny_train = train_data['xt']\nX_test = test_data[['xt-4', 'xt-3', 'xt-2', 'xt-1']]\ny_test = test_data['xt']\n\n# 3. Membuat dan melatih model Regresi Linier dengan Bagging\nlinear_reg = LinearRegression()  # Model Linear Regression\nmodel = BaggingRegressor(base_estimator=linear_reg, n_estimators=100, random_state=42)  # 10 estimator Linear Regression\nmodel.fit(X_train, y_train)\n\n# 4. Melakukan prediksi\ny_pred = model.predict(X_test)\n\n# 5. Menghitung metrik evaluasi\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Root Mean Squared Error\nmape = mean_absolute_percentage_error(y_test, y_pred)  # Mean Absolute Percentage Error\n\n# 6. Menampilkan hasil evaluasi\nprint(f\"RMSE: {rmse}\")\nprint(f\"MAPE: {mape * 100:.2f}%\")  # Dalam persen\n\n# 7. Menampilkan hasil prediksi dan actual values\nresults = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nprint(results)\n","block_group":"58fd37387bda45faaf61431921aaa58d","execution_count":7,"outputs":[{"name":"stdout","text":"RMSE: 0.0962038006828323\nMAPE: 10.96%\n      Actual  Predicted\n0   0.664273   0.647537\n1   0.958216   0.847154\n2   0.799960   0.741561\n3   0.629912   0.708820\n4   0.749894   0.749919\n5   0.605774   0.566515\n6   0.960218   0.831236\n7   0.568268   0.607243\n8   0.799322   0.721541\n9   0.677783   0.680423\n10  0.265740   0.265300\n11  0.862089   0.726004\n12  0.842168   0.735622\n13  0.961624   0.818777\n14  0.731854   0.827274\n15  0.530954   0.568302\n16  0.743098   0.631608\n17  0.779765   0.711554\n18  0.793387   0.692847\n19  0.676408   0.750895\n20  0.781697   0.741852\n21  0.958044   0.833687\n22  0.641470   0.612325\n23  0.906775   0.757816\n24  0.624118   0.784494\n25  0.721256   0.666899\n26  0.652563   0.653464\n27  0.639519   0.603672\n28  0.634533   0.609874\n29  0.534998   0.689663\n30  0.875923   0.789011\n31  0.511397   0.650626\n32  0.444635   0.549695\n33  0.853281   0.632044\n34  0.713732   0.743835\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/2787ccf9-63f3-4d79-825a-bf174fb7ad0c","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4cc01fa6db7045f4910670be92fca396","deepnote_cell_type":"text-cell-p"},"source":"untuk hasil prediksi menggunakan model ensemble bagging dengan regresi linier dan estimator = 100 menunjukkan kinerja yang cukup baik. Nilai RMSE sebesar 0.0962 menandakan bahwa kesalahan prediksi model relatif kecil, sementara MAPE sebesar 10.96% menunjukkan bahwa rata-rata kesalahan prediksi sekitar 10.96% dari nilai sebenarnya. Secara keseluruhan, model ini sudah cukup akurat dan dapat diandalkan, meskipun masih ada kemungkinan untuk meningkatkan akurasi lebih lanjut.","block_group":"2849d095af474ccba55dcebffc7525e8"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"044f7412024742c1a706716522343f34","deepnote_cell_type":"text-cell-h3"},"source":"### 4.2 metode SVR","block_group":"8c84f921a6824bfd894a24777b53229a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0b0cc2ad0afd4969bf8e839d91141532","deepnote_cell_type":"text-cell-p"},"source":"Support Vector Regression (SVR) adalah metode regresi yang menggunakan prinsip dari Support Vector Machine (SVM) yang umumnya digunakan untuk klasifikasi. Dalam SVR, tujuannya adalah untuk memprediksi nilai kontinu berdasarkan data yang diberikan. SVR berusaha menemukan hyperplane yang meminimalkan error dalam prediksi, dengan mempertimbangkan margin toleransi yang ditentukan oleh parameter epsilon","block_group":"e792c7931f4e47fbabf7958645d9eb9d"},{"cell_type":"code","metadata":{"source_hash":"435b635d","execution_start":1733637868129,"execution_millis":528,"execution_context_id":"dd8e3d77-baab-41ad-ab32-d8bd44221b1a","cell_id":"3c944369ef5543acaf72e1fccb936b59","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n\n# 1. Memuat data train dan test\ntrain_data = pd.read_csv('train_data.csv')\ntest_data = pd.read_csv('test_data.csv')\n\n# 2. Memisahkan fitur dan target\nX_train = train_data[['xt-4', 'xt-3', 'xt-2', 'xt-1']]\ny_train = train_data['xt']\nX_test = test_data[['xt-4', 'xt-3', 'xt-2', 'xt-1']]\ny_test = test_data['xt']\n\n# 3. Membuat dan melatih model SVR dengan parameter epsilon\nepsilon = 0.1  # Menambahkan nilai epsilon\nmodel = SVR(kernel='rbf', epsilon=epsilon)  # Menggunakan kernel RBF dan parameter epsilon\nmodel.fit(X_train, y_train)\n\n# 4. Melakukan prediksi\ny_pred = model.predict(X_test)\n\n# 5. Menghitung metrik evaluasi\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Root Mean Squared Error\nmape = mean_absolute_percentage_error(y_test, y_pred)  # Mean Absolute Percentage Error\n\n# 6. Menampilkan hasil evaluasi\nprint(f\"RMSE: {rmse}\")\nprint(f\"MAPE: {mape * 100:.2f}%\")  # Dalam persen\n\n# 7. Menampilkan hasil prediksi dan actual values\nresults = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nprint(results)\n","block_group":"20b5525199674d2c817dfb9d56437340","execution_count":10,"outputs":[{"name":"stdout","text":"RMSE: 0.10920325532730323\nMAPE: 13.24%\n      Actual  Predicted\n0   0.664273   0.622680\n1   0.958216   0.835389\n2   0.799960   0.715876\n3   0.629912   0.757105\n4   0.749894   0.726218\n5   0.605774   0.534003\n6   0.960218   0.784648\n7   0.568268   0.542987\n8   0.799322   0.747479\n9   0.677783   0.665660\n10  0.265740   0.370575\n11  0.862089   0.678554\n12  0.842168   0.773211\n13  0.961624   0.758724\n14  0.731854   0.754524\n15  0.530954   0.566286\n16  0.743098   0.684740\n17  0.779765   0.769924\n18  0.793387   0.675156\n19  0.676408   0.780979\n20  0.781697   0.706009\n21  0.958044   0.861714\n22  0.641470   0.607336\n23  0.906775   0.759422\n24  0.624118   0.788873\n25  0.721256   0.720448\n26  0.652563   0.553229\n27  0.639519   0.608238\n28  0.634533   0.532572\n29  0.534998   0.713114\n30  0.875923   0.830527\n31  0.511397   0.622426\n32  0.444635   0.596879\n33  0.853281   0.606489\n34  0.713732   0.721724\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/5249eadd-cb38-42a2-948d-81777ff66f77","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2176d6ec21bc43588f9ec8846f97df75","deepnote_cell_type":"text-cell-p"},"source":"Hasil prediksi menggunakan SVR (Support Vector Regression) menggunkan kernel rbf dan epsilon = 0.1 menunjukkan nilai RMSE sebesar 0.1092 dan MAPE sebesar 13.24%, yang lebih tinggi dibandingkan dengan model ensemble bagging dengan regresi linier.","block_group":"da9731c9ebc546e28f9ef4d09a6041f5"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a2a6eef1a7be49efa025d15a3dffe9c9","deepnote_cell_type":"text-cell-h3"},"source":"### 4.3. Melakukan Prediksi Single Step ","block_group":"96e058cca7a84b4a9007a6f2c631e580"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5cc0f350b626411db55e323c18fc3cfd","deepnote_cell_type":"text-cell-p"},"source":"Dikarenakan hasil dari model ensemble bagging lebih rendah, saya memutuskan untuk menggunakan metode ensemble bagging untuk prediksi single step","block_group":"1e2c8eaa58fc4c7383e393ee4e89afda"},{"cell_type":"code","metadata":{"source_hash":"e6ee0116","execution_start":1733631081609,"execution_millis":410,"execution_context_id":"dd8e3d77-baab-41ad-ab32-d8bd44221b1a","cell_id":"f07f567f98d646c29cc961e55ed5a0bf","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\n# 1. Memuat data train dan test\ntrain_data = pd.read_csv('train_data.csv')\ntest_data = pd.read_csv('test_data.csv')\n\n# 2. Memisahkan fitur (X) dan target (y) untuk data latih dan uji\nX_train = train_data[['xt-4', 'xt-3', 'xt-2', 'xt-1']]  # Fitur untuk data latih\ny_train = train_data['xt']  # Target untuk data latih\n\nX_test = test_data[['xt-4', 'xt-3', 'xt-2', 'xt-1']]  # Fitur untuk data uji\ny_test = test_data['xt']  # Target untuk data uji\n\n# 3. Membuat model Bagging dengan Linear Regression sebagai estimator\nbase_model_lr = LinearRegression()\nbagging_model_lr = BaggingRegressor(base_estimator=base_model_lr, n_estimators=100, random_state=42)\n\n# 4. Melatih model dengan data latih\nbagging_model_lr.fit(X_train, y_train)\n\n# 5. Memprediksi data uji\ny_pred_lr = bagging_model_lr.predict(X_test)\n\n# 6. Evaluasi model\nmse_lr = mean_squared_error(y_test, y_pred_lr)\nr2_lr = r2_score(y_test, y_pred_lr)\nmape_lr = (abs((y_test - y_pred_lr) / y_test).mean()) * 100\n\n# 7. Menampilkan hasil evaluasi\nprint(f\"Linear Regression - MSE: {mse_lr:.2f}, R2 Score: {r2_lr:.2f}, MAPE: {mape_lr:.2f}%\")\n\n# 8. Menampilkan prediksi data uji\noutput_predictions = pd.DataFrame({\n    'Actual': y_test,\n    'Predicted_LR': y_pred_lr\n})\nprint(\"\\nPrediksi Data Uji:\")\nprint(output_predictions)\n\n# 9. Prediksi single step bulan selanjutnya\n# Inputan yang diberikan: xt-4, xt-3, xt-2, xt-1\ninput_data = np.array([0.7338254626352513, 0.714743654565679, 0.8782283345130953, 0.7461725149155627]).reshape(1, -1)\n\n# Prediksi bulan selanjutnya menggunakan model\nnext_prediction = bagging_model_lr.predict(input_data)\n\n# Menyiapkan data baru untuk prediksi berikutnya\nnew_row = {\n    'xt-4': input_data[0][0],  # xt-4\n    'xt-3': input_data[0][1],  # xt-3\n    'xt-2': input_data[0][2],  # xt-2\n    'xt-1': input_data[0][3],  # xt-1\n    'xt': next_prediction[0]   # Prediksi menjadi xt\n}\n\n# Menampilkan data baru untuk prediksi bulan berikutnya\nprint(\"\\nData baru yang disiapkan untuk bulan berikutnya:\")\nprint(pd.DataFrame([new_row]))\n","block_group":"b0eaa5c479c34c71ab796666850a200a","execution_count":8,"outputs":[{"name":"stdout","text":"Linear Regression - MSE: 0.01, R2 Score: 0.62, MAPE: 10.96%\n\nPrediksi Data Uji:\n      Actual  Predicted_LR\n0   0.664273      0.647537\n1   0.958216      0.847154\n2   0.799960      0.741561\n3   0.629912      0.708820\n4   0.749894      0.749919\n5   0.605774      0.566515\n6   0.960218      0.831236\n7   0.568268      0.607243\n8   0.799322      0.721541\n9   0.677783      0.680423\n10  0.265740      0.265300\n11  0.862089      0.726004\n12  0.842168      0.735622\n13  0.961624      0.818777\n14  0.731854      0.827274\n15  0.530954      0.568302\n16  0.743098      0.631608\n17  0.779765      0.711554\n18  0.793387      0.692847\n19  0.676408      0.750895\n20  0.781697      0.741852\n21  0.958044      0.833687\n22  0.641470      0.612325\n23  0.906775      0.757816\n24  0.624118      0.784494\n25  0.721256      0.666899\n26  0.652563      0.653464\n27  0.639519      0.603672\n28  0.634533      0.609874\n29  0.534998      0.689663\n30  0.875923      0.789011\n31  0.511397      0.650626\n32  0.444635      0.549695\n33  0.853281      0.632044\n34  0.713732      0.743835\n\nData baru yang disiapkan untuk bulan berikutnya:\n       xt-4      xt-3      xt-2      xt-1        xt\n0  0.733825  0.714744  0.878228  0.746173  0.750895\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BaggingRegressor was fitted with feature names\n  warnings.warn(\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/de36eb2e-80ea-471b-a4a0-3158d2345b4d","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"4a979ee1","execution_start":1733641770033,"execution_millis":0,"execution_context_id":"dd8e3d77-baab-41ad-ab32-d8bd44221b1a","cell_id":"ffa8eddb82474b54b169a5647332ac48","deepnote_cell_type":"code"},"source":"# Nilai minimum dan maksimum untuk unnormalisasi\nx_min = 17083  # Contoh: nilai minimum dari data asli\nx_max = 115973  # Contoh: nilai maksimum dari data asli\n\n# Unnormalisasi hasil prediksi\nunnormalized_next_prediction = next_prediction[0] * (x_max - x_min) + x_min\n\n# Membulatkan hasil ke bilangan bulat\nunnormalized_next_prediction = round(unnormalized_next_prediction)\n\n# Menampilkan hasil prediksi unnormalisasi sebagai bilangan bulat\nprint(\"\\nPrediksi bulan berikutnya (unnormalisasi):\")\nprint(f\"{unnormalized_next_prediction} unit\")\n","block_group":"48986e94d99f43dc851676c42760745e","execution_count":13,"outputs":[{"name":"stdout","text":"\nPrediksi bulan berikutnya (unnormalisasi):\n91339 unit\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/95c0ba78-67c3-4c62-b0fe-e669a6644d75","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"978e4cdc","execution_start":1733673904814,"execution_millis":262,"execution_context_id":"5c89559f-29a5-4d5e-af5e-e1a34d3f8bf4","cell_id":"b0d1a38ac0dd46b292d06933e45beb2a","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\nfrom joblib import load\n\n# 1. Memuat model dari file\nmodel_filename = 'bagging_model_p2.joblib'\nloaded_model = load(model_filename)\nprint(f\"Model berhasil dimuat dari file: {model_filename}\")\n\n# 2. Data baru untuk prediksi (format: xt-4, xt-3, xt-2, xt-1)\ninput_data = np.array([0.7338254626352513, 0.714743654565679, 0.8782283345130953, 0.7461725149155627]).reshape(1, -1)\n\n# 3. Prediksi dengan model yang dimuat\nnext_prediction = loaded_model.predict(input_data)\n\n# 4. Menampilkan prediksi\nprint(\"\\nHasil Prediksi untuk data baru:\")\nprint(f\"Prediksi Normalisasi: {next_prediction[0]:.4f}\")\n\n# 5. Unnormalisasi hasil prediksi\nx_min = 17083  # Contoh: nilai minimum dari data asli\nx_max = 115973  # Contoh: nilai maksimum dari data asli\n\n# Hasil prediksi unnormalisasi\nunnormalized_next_prediction = next_prediction[0] * (x_max - x_min) + x_min\n\n# Membulatkan hasil ke bilangan bulat\nunnormalized_next_prediction = round(unnormalized_next_prediction)\n\nprint(f\"Prediksi bulan berikutnya (unnormalisasi): {unnormalized_next_prediction} unit\")\n","block_group":"c7c19e4ed6eb4339b9612f9d96bf931b","execution_count":3,"outputs":[{"name":"stdout","text":"Model berhasil dimuat dari file: bagging_model_p2.joblib\n\nHasil Prediksi untuk data baru:\nPrediksi Normalisasi: 0.7509\nPrediksi bulan berikutnya (unnormalisasi): 91339 pasien\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BaggingRegressor was fitted with feature names\n  warnings.warn(\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/cbf2f9be-a5e4-4448-8661-e1ee8d57559d","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a6caf570b1974b10b42c7844648e1393","deepnote_cell_type":"text-cell-h2"},"source":"## 5. Evaluasi","block_group":"ed977faf0a404795b6b7b6f3b3832e96"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0a42b76396224d269740f88172eb6887","deepnote_cell_type":"text-cell-p"},"source":"Evaluasi dari kedua model prediksi menunjukkan perbedaan performa yang signifikan. Model ensemble bagging dengan regresi linier menghasilkan RMSE sebesar 0.0962 dan MAPE sebesar 10.96%, yang menunjukkan kesalahan prediksi yang relatif kecil dan deviasi rata-rata yang terkontrol, menjadikannya model yang lebih akurat dan dapat diandalkan untuk prediksi. Di sisi lain, model SVR (Support Vector Regression) menghasilkan RMSE sebesar 0.1092 dan MAPE sebesar 13.24%, yang sedikit lebih tinggi, menunjukkan bahwa kesalahan prediksi dan deviasi rata-rata antara nilai prediksi dan aktual lebih besar dibandingkan dengan model ensemble bagging. Secara keseluruhan, meskipun kedua model memiliki potensi untuk digunakan, ensemble bagging terbukti lebih efektif dalam menghasilkan prediksi yang lebih akurat pada dataset ini, meskipun keduanya masih memiliki ruang untuk perbaikan lebih lanjut.","block_group":"e6a386efe12f4ca199bd4da15800ad17"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7bc9c7328b9944f089433d3706672cbf","deepnote_cell_type":"text-cell-h2"},"source":"## 6. deploy","block_group":"c200734cfcf0486a988c3461a59e6a24"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d71500c2-b449-45af-bb9d-9851cba6cfbc' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-12-08T16:30:15.488Z"},"deepnote_notebook_id":"0776d72492da47cc826ef04407fd380a"}}