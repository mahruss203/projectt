{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0be1471f2ccf442ea99fe5592c96c564","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"8deadd448fb346c58064b3416f4e1f85"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6355a962b7c842b2ba5613e18985d06e","deepnote_cell_type":"text-cell-h1"},"source":"# Prediksi Harga Penutupan Saham PT Sidomuncul Menggunakan Model Pembelajaran Mesin","block_group":"b2628082881940f48f2a1fe23772dc12"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ce82c86b598a4ff9a56e44ff30390794","deepnote_cell_type":"text-cell-h2"},"source":"## 1. memahami Bisnis","block_group":"248e537a2d1a4582b7ed1089d4209461"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c349a896bf604b2799a7aa72db8cc64c","deepnote_cell_type":"text-cell-p"},"source":"Industri pasar saham, khususnya perusahaan publik, menghadapi tantangan besar dalam menghadapi volatilitas pasar dan tuntutan terhadap kinerja keuangan yang semakin tinggi. Dalam beberapa tahun terakhir, permintaan terhadap investasi saham terus berkembang seiring dengan pertumbuhan ekonomi, peningkatan kesadaran investasi, serta perubahan demografi yang memengaruhi pola konsumsi. Namun, fluktuasi harga saham yang tidak terduga, terutama prediksi harga penutupan saham, dapat membebani investor dan mempengaruhi keputusan investasi. Oleh karena itu, prediksi harga penutupan saham menjadi hal yang sangat penting untuk mengoptimalkan strategi investasi dan meminimalkan risiko.","block_group":"4dac1cead0f14db0bac9d50311c251ef"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7fb64ea0fa654032a723c414b37bb7ce","deepnote_cell_type":"text-cell-p"},"source":"Visi perusahaan kami adalah menjadi penyedia solusi investasi terkemuka yang mampu memanfaatkan teknologi analitik untuk meningkatkan efisiensi keputusan investasi dan mengoptimalkan kinerja portofolio. Untuk mencapai visi tersebut, misi kami adalah mengembangkan dan memanfaatkan sistem prediksi berbasis data untuk meramalkan harga penutupan saham secara lebih akurat, menyediakan solusi analitik yang dapat membantu investor dalam pengambilan keputusan yang lebih efektif, serta meningkatkan pemahaman terhadap tren pasar untuk mendukung pengelolaan portofolio yang lebih cerdas.","block_group":"d09755c31c2c4f599d819fe218af05cc"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b48b81701e6d4825bbb61d441d331f49","deepnote_cell_type":"text-cell-p"},"source":"Strategi bisnis yang kami terapkan fokus pada pemanfaatan teknologi untuk memahami pola pergerakan harga saham dan tren pasar. Dengan menggunakan analisis data yang mendalam, perusahaan kami berkomitmen untuk memberikan wawasan yang lebih tepat dalam meramalkan harga penutupan saham dan mendukung investor dalam mengambil keputusan yang lebih cerdas.","block_group":"907a83f3a74a41ee82d0117cc8aa5679"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"6ca353c17bf14db98b6dd050e30a7745","deepnote_cell_type":"text-cell-h3"},"source":"### 1.1. tujuan Bisnis","block_group":"3f369866da754f3a8cac68849b5aec6e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d8dddcb691a04518b337db4a984237c3","deepnote_cell_type":"text-cell-bullet"},"source":"- Meningkatkan Akurasi Prediksi Harga Saham: Menggunakan algoritma machine learning untuk memprediksi harga penutupan saham PT Sidomuncul dengan lebih akurat.","block_group":"62a1f607b19341bbaa26796e382feba9"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a48e8ef108c046d3836914f8abc7cdce","deepnote_cell_type":"text-cell-bullet"},"source":"- Optimalkan Model: Mengembangkan model prediksi harga saham yang terus belajar dan beradaptasi dengan perubahan kondisi pasar dan faktor-faktor eksternal yang mempengaruhi pergerakan saham.","block_group":"36763caae101482fb24789dcbacc774a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c1119ac5b06543c39f725da32ab74443","deepnote_cell_type":"text-cell-bullet"},"source":"- Pengelolaan Portofolio Investasi: Membantu merencanakan alokasi investasi dan strategi perdagangan berdasarkan prediksi harga saham untuk memaksimalkan keuntungan dan meminimalkan risiko.","block_group":"96800c5a98a7403aa83f72c910cd83d0"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9c8f2f0e3d564064ae386d1a1a6bfe5e","deepnote_cell_type":"text-cell-h3"},"source":"### 1.2. Permasalahan Analisis bisnis","block_group":"10a542fd46ce4438886ef85c0c8ed959"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"44059e00e0484af0ba7eccf278fd04a8","deepnote_cell_type":"text-cell-bullet"},"source":"- Melakukan analisis Tren Harga Saham: Menggunakan metode machine learning untuk memprediksi pola pergerakan harga saham PT Sidomuncul dengan lebih akurat.","block_group":"7643271aa7ca4e35803ef1170ba92898"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"fe3f81ab9f154ce98eb2799669ba7b02","deepnote_cell_type":"text-cell-bullet"},"source":"- Menentukan Algoritma Machine Learning Terbaik: Mencari dan memilih algoritma machine learning yang paling efektif untuk memprediksi harga penutupan saham dengan akurasi tinggi, berdasarkan data historis dan faktor-faktor pasar terkait.","block_group":"03db52ebc024420f8ea3db2f32a603ca"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7c2ee8b2a7884caf9d7dc5dddf2ce054","deepnote_cell_type":"text-cell-h2"},"source":"## 2. memahami data","block_group":"2e1f55be40294478a4cd9cc847d0032e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9d585d5c56ab4a58b447627d94398281","deepnote_cell_type":"text-cell-h3"},"source":"### 2.1. Deskripsi Data","block_group":"69ee84be14d74ba9a10ddb46c3b674b5"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0d159f7ebb2042bc85a54f2a38d1f814","deepnote_cell_type":"text-cell-p"},"source":"Dataset yang Anda gunakan mencakup data harian dari tahun 2022 hingga 2024, dengan total 709 record, dan mencakup fitur-fitur penting seperti 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', dan 'AdjustedClose'. Data ini sangat berpotensi untuk analisis pergerakan pasar saham, terutama dalam memprediksi harga penutupan saham menggunakan model machine learning berbasis time series. Dengan memanfaatkan data ini ","block_group":"4e2ffe3d684e4023a352ff8698990e9a"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"url":"https://investor.sidomuncul.co.id/id/historical_price.html","type":"link","ranges":[],"toCodePoint":58,"fromCodePoint":0}],"cell_id":"5f9afa65147b4e16983413cf97de7a2b","deepnote_cell_type":"text-cell-p"},"source":"https://investor.sidomuncul.co.id/id/historical_price.html","block_group":"26f406a2d24d4620bd21368495b2b3fc"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"be92bf6ca3d74106990f339c20d550cb","deepnote_cell_type":"text-cell-h3"},"source":"### 2.2. tipe data","block_group":"034ac94267dd4051aea005ae599e768b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"cc4a4f698e54478d903c920db1494927","deepnote_cell_type":"text-cell-p"},"source":"Dataset yang kita gunakan memiliki beberapa atribut dengan tipe data berbeda. Date bertipe data Date (tanggal), yang merepresentasikan informasi tanggal dalam format waktu seperti YYYY-MM-DD dan digunakan sebagai penanda waktu untuk analisis berbasis time series.","block_group":"1081c1d480c2422487c21c0c46206982"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5b91893f37674be28d78218ca7e105a0","deepnote_cell_type":"text-cell-p"},"source":"Atribut lainnya, yaitu Open, High, Low, Close, dan AdjustedClose, semuanya bertipe Integer (bilangan bulat). Atribut-atribut ini mencatat harga saham pada berbagai titik waktu perdagangan, mulai dari harga pembukaan, tertinggi, terendah, penutupan, hingga harga penutupan yang telah disesuaikan dengan pembagian saham atau dividen.","block_group":"87b3966f72204a2a9b3be67bc01efa57"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c05852fc62ce4966a91ed91972b12b73","deepnote_cell_type":"text-cell-p"},"source":"Selain itu, ada atribut Volume, juga bertipe Integer, yang mencatat jumlah total saham yang diperdagangkan setiap harinya. Atribut ini penting untuk menunjukkan likuiditas pasar pada hari tertentu.","block_group":"c146ea63f61b4a7b8f0ba1ca43778c49"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3d0cdfde580e4ec38689ecbc16095cb1","deepnote_cell_type":"text-cell-h3"},"source":"### 2.3 Mengambil Data","block_group":"57dcfa371b3247fb9cc3f930f6e95015"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"92cabfd3c5d04173a03a01dcf067f6d9","deepnote_cell_type":"text-cell-p"},"source":"Untuk mengambil data dari file CSV, kita dapat menggunakan library pandas. Pandas menyediakan fungsi read_csv() yang memungkinkan kita untuk membaca file CSV dan mengubahnya menjadi DataFrame, yang memudahkan kita untuk mengelola dan menganalisis data.","block_group":"ccfbf0153e484c9abe682017a1179aaf"},{"cell_type":"code","metadata":{"source_hash":"41faef4a","execution_start":1733658801372,"execution_millis":215,"execution_context_id":"20165fcd-d12f-4d25-bf35-3c54f13ce7c9","cell_id":"6ef8c323a2674f098d35687af5aa2c69","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# Ganti '.csv' dengan path ke file CSV kamu\nfile_path = 'projectp3.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Menampilkan DataFrame\nprint(df)\n","block_group":"e633286288354ad5892debbe8d789569","execution_count":3,"outputs":[{"name":"stdout","text":"         Date  Open  High  Low  Close    Volume  AdjustedClose\n0    20220103   865   875  865    870   4962600            870\n1    20220104   870   910  865    900  17952800            900\n2    20220105   905   915  900    910  18710800            910\n3    20220106   910   930  910    925  14432900            925\n4    20220107   925   970  925    950  24948100            950\n..        ...   ...   ...  ...    ...       ...            ...\n703  20241202   575   590  570    580  21439600            580\n704  20241203   585   590  580    580  14839600            580\n705  20241204   580   590  580    580   9563500            580\n706  20241205   580   590  580    585   3381000            585\n707  20241206   580   585  575    580  13704200            580\n\n[708 rows x 7 columns]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/18af7fa6-36ef-4454-b7c7-ee0ba1ce4497","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4e0e136b65e24d30a2f710aabc007acf","deepnote_cell_type":"text-cell-h2"},"source":"## 3. procesing data","block_group":"dbcb5dabb99842218faeac9c41aad216"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":366,"fromCodePoint":337},{"type":"marks","marks":{"bold":true},"toCodePoint":412,"fromCodePoint":395},{"type":"marks","marks":{"bold":true},"toCodePoint":467,"fromCodePoint":415}],"cell_id":"974f14a15ef9446c83070643e3cdae47","deepnote_cell_type":"text-cell-p"},"source":"Tujuan dari proses pengolahan data (data processing) adalah untuk menyiapkan data dalam bentuk yang dapat digunakan untuk analisis atau pembuatan model prediksi. Proses ini mencakup berbagai langkah yang bertujuan untuk memastikan data yang digunakan memiliki kualitas yang baik, relevan, dan siap digunakan. Pada data yang saya gunakan tidak terdapat missing value sehingga saya hanya melakukan Normalisasi data , korelasi , dan penghapus fitur yang tidak diperlukan","block_group":"977cdc991ebf4ff8bb76baf42755de47"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c05db84eb158482e9f54e9bc34dc1c68","deepnote_cell_type":"text-cell-h3"},"source":"### 3.1 korelasi Person","block_group":"08c931ee9087446fb72b3f3b664f6e40"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"999a21c1f5e14a8184c9b05d7346e747","deepnote_cell_type":"text-cell-p"},"source":"Korelasi Pearson adalah ukuran statistik yang digunakan untuk mengukur kekuatan dan arah hubungan linier antara dua variabel. Nilai korelasi Pearson dinyatakan dalam rentang -1 hingga 1, dengan interpretasi sebagai berikut","block_group":"b8b66ad1e4054ff7aa9399236861aeef"},{"cell_type":"code","metadata":{"source_hash":"3aaa5be2","execution_start":1733658865840,"execution_millis":117,"execution_context_id":"20165fcd-d12f-4d25-bf35-3c54f13ce7c9","cell_id":"22d1d19d9cf248d0a994d8114ff877ec","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# Ganti path file dengan file Anda\nfile_path = 'projectp3.csv'  # Ganti dengan path file CSV Anda\ndf = pd.read_csv(file_path)\n\n# Langkah 3: Hitung korelasi Pearson\ncorrelation_matrix = df.corr(method='pearson')\nprint(\"Matriks Korelasi:\")\nprint(correlation_matrix)\n","block_group":"5459c75ff53d4eb9abed892c04a1ffab","execution_count":5,"outputs":[{"name":"stdout","text":"Matriks Korelasi:\n                   Date      Open      High       Low     Close    Volume  \\\nDate           1.000000 -0.638365 -0.638363 -0.641623 -0.635731  0.060542   \nOpen          -0.638365  1.000000  0.997825  0.997682  0.995757 -0.097434   \nHigh          -0.638363  0.997825  1.000000  0.997214  0.997795 -0.075217   \nLow           -0.641623  0.997682  0.997214  1.000000  0.998038 -0.120273   \nClose         -0.635731  0.995757  0.997795  0.998038  1.000000 -0.104868   \nVolume         0.060542 -0.097434 -0.075217 -0.120273 -0.104868  1.000000   \nAdjustedClose -0.635731  0.995757  0.997795  0.998038  1.000000 -0.104868   \n\n               AdjustedClose  \nDate               -0.635731  \nOpen                0.995757  \nHigh                0.997795  \nLow                 0.998038  \nClose               1.000000  \nVolume             -0.104868  \nAdjustedClose       1.000000  \n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/24b9bbb3-9e86-4684-99e0-35b3995980f9","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c809febba3654a5eb801209e40aad1f4","deepnote_cell_type":"text-cell-p"},"source":"Dari matriks korelasi yang diberikan, terlihat bahwa beberapa atribut memiliki hubungan positif yang sangat kuat dengan harga penutupan (Close), yaitu dengan nilai korelasi lebih dari 0,7. Atribut Open memiliki korelasi sebesar 0,995757, menunjukkan hubungan yang sangat kuat antara harga pembukaan dengan harga penutupan saham. Hal ini mengindikasikan bahwa pergerakan harga pada awal perdagangan sangat terkait dengan harga penutupan. Selanjutnya, atribut High menunjukkan korelasi sebesar 0,997795, yang berarti bahwa harga tertinggi yang dicapai selama perdagangan memiliki hubungan yang signifikan dengan harga penutupan. Demikian pula, atribut Low memiliki korelasi sebesar 0,998038, menandakan bahwa harga terendah dalam suatu hari perdagangan sangat memengaruhi harga penutupan. ","block_group":"7f1f6519d7684dce805b58c36cd5bb64"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6c261c5d59cc434bb7c0a6b80d2edb55","deepnote_cell_type":"text-cell-p"},"source":"Dengan demikian, atribut-atribut Open, High, dan Low. merupakan prediktor utama yang sangat relevan untuk digunakan dalam memodelkan dan memprediksi harga penutupan saham. AdjustedClose yang memiliki korelasi sempurna dapat menjadi pengganti langsung untuk Close dalam analisis lebih lanjut.","block_group":"bf59aa268d454e0090336b06105bba98"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c8ff553a7fa544789643e8a3f1f1af25","deepnote_cell_type":"text-cell-h3"},"source":"### 3.2. penghapusan fitur","block_group":"88d63a495bc8477da73c3b1a888c0b30"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":false,"cell_id":"f7504825fbbf4872ac0c9559874ea0e3","deepnote_cell_type":"text-cell-p"},"source":"penghapusan kolom yang nilai korelasinya lebih rendah dari 0,7  maka akan di hapus :","block_group":"7ce21f9f010f4612b2bf5101cdfca64e"},{"cell_type":"code","metadata":{"source_hash":"be872226","execution_start":1733658991756,"execution_millis":244,"execution_context_id":"20165fcd-d12f-4d25-bf35-3c54f13ce7c9","cell_id":"5d0fa60d278846d9ab6f05f418b7eace","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# Ganti '.csv' dengan path ke file CSV kamu\nfile_path = 'projectp3.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Menghapus kolom 'Date', 'Volume', dan 'AdjustedClose'\ndf = df.drop(columns=['Date', 'Volume', 'AdjustedClose'])\n\n# Menyimpan DataFrame ke file CSV baru\noutput_file_path = 'project3.csv'\ndf.to_csv(output_file_path, index=False)\n\nprint(f\"DataFrame telah disimpan ke {output_file_path}\")\n","block_group":"f5d76067006e4f57960709ab54456d59","execution_count":6,"outputs":[{"name":"stdout","text":"DataFrame telah disimpan ke project3.csv\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/ad89875b-bc98-4703-a56b-3491b914fcec","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d8a2b6cf8b06474b808fefb427733613","deepnote_cell_type":"text-cell-h3"},"source":"### 3.3. Normalisasi Data","block_group":"0a61edb249c449adac94e44b05c5fb14"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"350861773d044e0b8271387c0c51f36f","deepnote_cell_type":"text-cell-p"},"source":"Untuk memastikan bahwa data yang digunakan dalam model prediksi berada dalam skala yang sama, kita dapat melakukan normalisasi menggunakan teknik MinMaxScaler. Teknik ini mengubah nilai-nilai dalam fitur menjadi rentang antara 0 dan 1, yang membantu meningkatkan kinerja model","block_group":"b7fd0b2fdc86480391dc91d690970a5e"},{"cell_type":"code","metadata":{"source_hash":"fde41057","execution_start":1733680154920,"execution_millis":180,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"dcf0b59fea8e4a60ac8ca738c5994807","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# Ganti '.csv' dengan path ke file CSV kamu\nfile_path = 'project3.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Menampilkan nilai minimum dan maksimum untuk setiap kolom\nmin_values = df.min()\nmax_values = df.max()\n\n# Menampilkan hasil\nprint(\"Nilai Minimum Setiap Kolom:\")\nprint(min_values)\n\nprint(\"\\nNilai Maksimum Setiap Kolom:\")\nprint(max_values)\n","block_group":"5d17b7eecf3049ea9e2c26185ef30ece","execution_count":16,"outputs":[{"name":"stdout","text":"Nilai Minimum Setiap Kolom:\nOpen     486\nHigh     494\nLow      478\nClose    486\ndtype: int64\n\nNilai Maksimum Setiap Kolom:\nOpen     1050\nHigh     1070\nLow      1040\nClose    1050\ndtype: int64\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/7ebee4ca-2bad-44b1-b163-8c02aec8d4a3","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"f141a4e9","execution_start":1733659022116,"execution_millis":898,"execution_context_id":"20165fcd-d12f-4d25-bf35-3c54f13ce7c9","cell_id":"d2b7442d70c24898b1311ea26717ea95","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Ganti '.csv' dengan path ke file CSV kamu\nfile_path = 'project3.csv'\n\n# Membaca file CSV\ndf = pd.read_csv(file_path)\n\n# Inisialisasi scaler\nscaler = MinMaxScaler()\n\n# Misalnya kita ingin menormalkan semua kolom kecuali kolom 'periode' yang mungkin berisi tanggal atau ID\n# Tentukan kolom mana yang akan dinormalisasi\nkolom_normalisasi = df.columns.difference(['periode'])  # Menghindari kolom yang tidak perlu dinormalisasi\n\n# Normalisasi data\ndf[kolom_normalisasi] = scaler.fit_transform(df[kolom_normalisasi])\n\n# Menyimpan DataFrame yang sudah dinormalisasi ke file CSV baru\ndf.to_csv('normalisasi_p3.csv', index=False)\n\n# Menampilkan DataFrame yang telah dinormalisasi\nprint(df)\n","block_group":"a7385ae8a09d4a75b68d03f6dd29958c","execution_count":7,"outputs":[{"name":"stdout","text":"         Open      High       Low     Close\n0    0.671986  0.661458  0.688612  0.680851\n1    0.680851  0.722222  0.688612  0.734043\n2    0.742908  0.730903  0.750890  0.751773\n3    0.751773  0.756944  0.768683  0.778369\n4    0.778369  0.826389  0.795374  0.822695\n..        ...       ...       ...       ...\n703  0.157801  0.166667  0.163701  0.166667\n704  0.175532  0.166667  0.181495  0.166667\n705  0.166667  0.166667  0.181495  0.166667\n706  0.166667  0.166667  0.181495  0.175532\n707  0.166667  0.157986  0.172598  0.166667\n\n[708 rows x 4 columns]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/ba46d36e-d379-42ef-873a-caf7ba6d6311","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"131ff08797fd4a4f8dfd6e10f3db3108","deepnote_cell_type":"text-cell-h2"},"source":"## 4. modelling","block_group":"029ae8b60d834ece97747610252e2b4a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"46682df3122d4ac4a48fac6569e0d636","deepnote_cell_type":"text-cell-p"},"source":"pemilihan model yang tepat dalam prediksi penjualan mobil adalah kunci untuk menghasilkan hasil yang akurat, karena setiap model memiliki keunggulan dan kelemahan tergantung pada jenis data dan tujuan analisis. Pemilihan model yang salah bisa menyebabkan prediksi yang kurang tepat, yang pada gilirannya dapat merugikan proses pengambilan keputusan. sebelum melakakukan modelling bagi data menjadi data train dan tes:","block_group":"db1680240d5247a7aaacf2473b26241d"},{"cell_type":"code","metadata":{"source_hash":"ccc7401e","execution_start":1733662825484,"execution_millis":412,"execution_context_id":"20165fcd-d12f-4d25-bf35-3c54f13ce7c9","cell_id":"7f0b4743372e468c93b3cc0c0062fc6a","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# 1. Memuat data dari CSV\ndata = pd.read_csv('normalisasi_p3.csv')\n\n# 2. Memisahkan data menjadi data training dan testing (80:20)\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# 3. Menyimpan data training dan testing ke dalam file CSV\ntrain_data.to_csv('train_data3.csv', index=False)\ntest_data.to_csv('test_data3.csv', index=False)\n\nprint(\"Data training dan testing berhasil disimpan ke file CSV.\")\n","block_group":"8166adf08988413d90175afa014f537f","execution_count":8,"outputs":[{"name":"stdout","text":"Data training dan testing berhasil disimpan ke file CSV.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/9196624e-d2ff-466d-bac2-8d3746c06b86","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2639c4d98a0f4bccabd3e3455c6cf51d","deepnote_cell_type":"text-cell-h3"},"source":"### 4.1 Ensemble Begging (tanpa sliding windows)","block_group":"ebb6f8dee47442a583aed2f605c8287a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"910d532a0b794819bda46e6e8e6d9056","deepnote_cell_type":"text-cell-p"},"source":"Metode ini digunakan untuk mengurangi variansi model dengan membangun banyak model pada subset acak dari data pelatihan, kemudian menggabungkan hasil prediksi dari model-model tersebut.","block_group":"f8165484e3fa449a98e07691e1f3d734"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":29,"fromCodePoint":0}],"cell_id":"b918ab923c034d43ba1e4cb030d09218","deepnote_cell_type":"text-cell-p"},"source":"4.1.1. single Step Prediction","block_group":"b15efe33051648128ef3e534a42404d0"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ccef10f2790d4ca2838efb79ebf7d588","deepnote_cell_type":"text-cell-p"},"source":"Single Step Prediction adalah pendekatan dalam time series forecasting di mana model memprediksi nilai target (output) hanya untuk satu langkah ke depan, berdasarkan nilai input yang tersedia.","block_group":"a041b49ab2124cd5af345976997f55e3"},{"cell_type":"code","metadata":{"source_hash":"2441669a","execution_start":1733665829608,"execution_millis":236,"execution_context_id":"20165fcd-d12f-4d25-bf35-3c54f13ce7c9","cell_id":"90f782cf381d4e88adc2e261c996420f","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n\n# Membaca file CSV data training dan testing\ntrain_data = pd.read_csv('train_data3.csv')\ntest_data = pd.read_csv('test_data3.csv')\n\n# Memisahkan fitur (Open, High, Low) dan target (Close) dari data training\nX_train = train_data[['Open', 'High', 'Low']].values\ny_train = train_data['Close'].values\n\n# Memisahkan fitur (Open, High, Low) dan target (Close) dari data testing\nX_test = test_data[['Open', 'High', 'Low']].values\ny_test = test_data['Close'].values\n\n# Model dasar menggunakan Linear Regression\nbase_model = LinearRegression()\n\n# Membuat model Bagging dengan estimator dasar Linear Regression\nbagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42)\n\n# Melatih model\nbagging_model.fit(X_train, y_train)\n\n# Melakukan prediksi pada data uji\npredictions = bagging_model.predict(X_test)\n\n# Menghitung metrik evaluasi\nmae = mean_absolute_error(y_test, predictions)\nrmse = np.sqrt(mean_squared_error(y_test, predictions))\nmape = mean_absolute_percentage_error(y_test, predictions)\n\n# Menampilkan hasil evaluasi\nprint(f\"MAE: {mae}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"MAPE: {mape * 100:.2f}%\")\n\n# Menyimpan hasil prediksi ke dalam DataFrame untuk output lengkap\nresults = pd.DataFrame({\n    'Actual': y_test,\n    'Predicted': predictions\n})\n\nprint(results)\n\n# Input data baru untuk prediksi (single-step)\nnew_data = np.array([[0.971986, 0.661458, 0.688612]])  # Input baru: Open, High, Low\n\n# Melakukan prediksi untuk data baru (single-step)\nnew_prediction = bagging_model.predict(new_data)\n\n# Menampilkan hasil prediksi untuk single-step\nprint(\"Prediksi untuk data baru:\", new_prediction)\n","block_group":"c5fd71c9f8af4e859a8dd7081b89cab3","execution_count":20,"outputs":[{"name":"stdout","text":"MAE: 0.008584473539814804\nRMSE: 0.011393898481661871\nMAPE: 2.61%\n       Actual  Predicted\n0    0.884752   0.882198\n1    0.459220   0.458346\n2    0.574468   0.571498\n3    0.450355   0.439903\n4    0.450355   0.439903\n..        ...        ...\n137  0.858156   0.848222\n138  0.831560   0.829779\n139  0.476950   0.465816\n140  0.973404   0.970969\n141  0.157801   0.165400\n\n[142 rows x 2 columns]\nPrediksi untuk data baru: [0.56087994]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/9c5c0439-e888-46e9-815c-083a0c4d6e36","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":37,"fromCodePoint":0}],"cell_id":"aeca89733d1e429daa7ca1b846923133","deepnote_cell_type":"text-cell-p"},"source":"4.1.2. Multi-Step Rekursif Prediction","block_group":"90e0d4825cb44655a22c216a03bfa503"},{"cell_type":"code","metadata":{"source_hash":"8975edf9","execution_start":1733671711046,"execution_millis":318,"execution_context_id":"4a47daa5-5ee9-4876-a7fc-62f14420b3d1","cell_id":"851a4121c91c4f8cadd21bdaec6bdc65","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n\n# Membaca file CSV data training dan testing\ntrain_data = pd.read_csv('train_data3.csv')\ntest_data = pd.read_csv('test_data3.csv')\n\n# Memisahkan fitur (Open, High, Low) dan target (Close) dari data training\nX_train = train_data[['Open', 'High', 'Low']].values\ny_train = train_data['Close'].values\n\n# Memisahkan fitur (Open, High, Low) dan target (Close) dari data testing\nX_test = test_data[['Open', 'High', 'Low']].values\ny_test = test_data['Close'].values\n\n# Model dasar menggunakan Linear Regression\nbase_model = LinearRegression()\n\n# Membuat model Bagging dengan estimator dasar Linear Regression\nbagging_model = BaggingRegressor(base_estimator=base_model, n_estimators=10, random_state=42)\n\n# Melatih model\nbagging_model.fit(X_train, y_train)\n\n# Fungsi untuk prediksi multi-step direct dengan mencetak input setiap langkah\ndef predict_multistep_direct(model, input_data, steps):\n    predictions = []\n    \n    # Melakukan prediksi untuk semua langkah ke depan\n    for step in range(steps):\n        print(f\"Input pada langkah {step + 1}: {input_data}\")  # Menampilkan input setiap langkah\n        \n        pred = model.predict(input_data)  # Prediksi untuk langkah selanjutnya\n        predictions.append(pred[0])  # Menyimpan hasil prediksi\n        \n        # Memperbarui input_data untuk langkah berikutnya\n        # Update input dengan prediksi yang baru saja didapat\n        input_data = np.array([[pred[0], input_data[0][1], input_data[0][2]]])  # Update input untuk langkah berikutnya\n    \n    return np.array(predictions)\n\n# Input data baru untuk prediksi (Open, High, Low)\nnew_data = np.array([[0.8315602836879432,0.8090277777777777,0.822064056939]])  # Ganti dengan data input baru: Open, High, Low\n\n# Menentukan jumlah langkah ke depan untuk prediksi (3 hari ke depan)\nmulti_step_steps = 3  # Prediksi 3 langkah ke depan (3 hari)\n\n# Menjalankan prediksi multi-step direct\nmulti_step_predictions = predict_multistep_direct(bagging_model, new_data, multi_step_steps)\n\n# Menampilkan hasil prediksi 3 hari selanjutnya\nprint(f\"Prediksi 3 Hari Selanjutnya untuk data baru:\", multi_step_predictions)\n\n# Evaluasi model dengan data uji\npredictions_test = bagging_model.predict(X_test)\n\n# Menghitung metrik evaluasi pada data uji\nmae = mean_absolute_error(y_test, predictions_test)\nrmse = np.sqrt(mean_squared_error(y_test, predictions_test))\nmape = mean_absolute_percentage_error(y_test, predictions_test)\n\n# Menampilkan hasil evaluasi\nprint(f\"MAE: {mae}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"MAPE: {mape * 100:.2f}%\")\n","block_group":"b8cc07d84c414d56b9a481524e8cc7b9","execution_count":6,"outputs":[{"name":"stdout","text":"Input pada langkah 1: [[0.83156028 0.80902778 0.82206406]]\nInput pada langkah 2: [[0.81865108 0.80902778 0.82206406]]\nInput pada langkah 3: [[0.82397696 0.80902778 0.82206406]]\nPrediksi 3 Hari Selanjutnya untuk data baru: [0.81865108 0.82397696 0.82177969]\nMAE: 0.008584473539814804\nRMSE: 0.011393898481661871\nMAPE: 2.61%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/ed9f9079-aee3-4dd9-9044-2263ad4dfb9a","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b5b3e35a45b14745ac66c79610a9ce4b","deepnote_cell_type":"text-cell-p"},"source":"Hasil prediksi multi-step menggunakan ensemble regresi linier menunjukkan performa model yang cukup baik dengan metrik evaluasi yang menjanjikan. Berdasarkan MAE (Mean Absolute Error) sebesar 0.0086, model ini menunjukkan kesalahan rata-rata yang kecil antara nilai prediksi dan nilai aktual. Selain itu, nilai RMSE (Root Mean Squared Error) sebesar 0.0114 menggambarkan bahwa kesalahan kuadrat rata-rata pada prediksi juga cukup rendah. Metrik MAPE (Mean Absolute Percentage Error) yang mencapai 2.61% menunjukkan bahwa kesalahan prediksi dalam bentuk persentase relatif terhadap nilai aktual cukup minimal, yang mengindikasikan akurasi model yang tinggi dalam memprediksi hasil multi-step.","block_group":"a4f9b924d201489d9ef45473c4d28174"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1d5cff507928445aa1bf8a4159376a1d","deepnote_cell_type":"text-cell-h3"},"source":"### 4.2 Ensemble begging (sliding windows)","block_group":"502746e272c14661a68d7486585eb332"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"da9a6b8614ce427cb7d467df53f3a0ef","deepnote_cell_type":"text-cell-p"},"source":"lakukan sliding windows dan pisah data ","block_group":"0724565767bb4bc6870e24462b65596e"},{"cell_type":"code","metadata":{"source_hash":"1184769f","execution_start":1733677598224,"execution_millis":365,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"f18049a6cf57407d943683d229330c3b","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\n\n# Fungsi untuk melakukan sliding window\ndef sliding_window(data, window_size):\n    X, y = [], []\n    for i in range(len(data) - window_size):\n        X.append(data[i:i+window_size, :-1])  # Fitur (Open, High, Low)\n        y.append(data[i+window_size-1, -1])  # Target (Close)\n    return np.array(X), np.array(y)\n\n# Menggabungkan fitur dan target dalam data training dan testing\ntrain_features = train_data[['Open', 'High', 'Low', 'Close']].values\ntest_features = test_data[['Open', 'High', 'Low', 'Close']].values\n\n# Menentukan ukuran window\nwindow_size = 4\n\n# Membuat sliding window untuk data training dan testing\nX_train, y_train = sliding_window(train_features, window_size)\nX_test, y_test = sliding_window(test_features, window_size)\n\n# Menyimpan hasil sliding window ke file CSV\ntrain_windowed = pd.DataFrame(np.hstack([X_train.reshape(X_train.shape[0], -1), y_train.reshape(-1, 1)]), columns=['Open_1', 'High_1', 'Low_1', 'Open_2', 'High_2', 'Low_2', 'Open_3', 'High_3', 'Low_3', 'Open_4', 'High_4', 'Low_4', 'Close'])\ntest_windowed = pd.DataFrame(np.hstack([X_test.reshape(X_test.shape[0], -1), y_test.reshape(-1, 1)]), columns=['Open_1', 'High_1', 'Low_1', 'Open_2', 'High_2', 'Low_2', 'Open_3', 'High_3', 'Low_3', 'Open_4', 'High_4', 'Low_4', 'Close'])\n\n# Menyimpan ke CSV\ntrain_windowed.to_csv('train_windowed.csv', index=False)\ntest_windowed.to_csv('test_windowed.csv', index=False)\n\nprint(\"Sliding window data has been saved to 'train_windowed.csv' and 'test_windowed.csv'.\")\n","block_group":"f75aaf7bbe48447c963b40b4d9d085b4","execution_count":2,"outputs":[{"name":"stdout","text":"Sliding window data has been saved to 'train_windowed.csv' and 'test_windowed.csv'.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/f5a67dc0-c077-4aaf-a6f2-7281473db612","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"b8033c76","execution_start":1733677952740,"execution_millis":449,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"a91033ecbcb64215b3ac105b9a508fea","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n\n# Membaca file CSV hasil sliding window\ntrain_windowed = pd.read_csv('train_windowed.csv')\ntest_windowed = pd.read_csv('test_windowed.csv')\n\n# Memisahkan fitur (Open_1, High_1, Low_1, ..., Open_4, High_4, Low_4) dan target (Close)\nX_train = train_windowed.drop(columns=['Close']).values\ny_train = train_windowed['Close'].values\nX_test = test_windowed.drop(columns=['Close']).values\ny_test = test_windowed['Close'].values\n\n# Membuat model Bagging dengan regresi linier sebagai estimator\nmodel = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=50, random_state=42)\n\n# Melatih model dengan data training\nmodel.fit(X_train, y_train)\n\n# Melakukan prediksi pada data testing\ny_pred = model.predict(X_test)\n\n# Menghitung metrik evaluasi\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nmape = mean_absolute_percentage_error(y_test, y_pred)\n\n# Menampilkan hasil evaluasi\nprint(f'Mean Squared Error: {mse}')\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Absolute Percentage Error: {mape}')\n\n# Menyimpan hasil prediksi ke dalam CSV\npredictions = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\npredictions.to_csv('predictions.csv', index=False)\n\nprint(predictions)\n","block_group":"44ed2db08da14e169048cea11d2ddad4","execution_count":4,"outputs":[{"name":"stdout","text":"Mean Squared Error: 0.00013946980980126148\nMean Absolute Error: 0.008859020561095823\nMean Absolute Percentage Error: 0.026224873810225452\n       Actual  Predicted\n0    0.450355   0.440686\n1    0.450355   0.440574\n2    0.423759   0.430145\n3    0.796099   0.781067\n4    0.991135   0.973884\n..        ...        ...\n133  0.671986   0.675926\n134  0.858156   0.845706\n135  0.831560   0.829224\n136  0.476950   0.462247\n137  0.973404   0.971338\n\n[138 rows x 2 columns]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/f6487522-4843-43e2-8190-981621d7c2b7","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b536f15c42a94a28bc70e8b6a1478e73","deepnote_cell_type":"text-cell-p"},"source":"memprediksi multi-step untuk data tes","block_group":"29f2e1adbfbe4b988ff9fd9fbfa90e21"},{"cell_type":"code","metadata":{"source_hash":"d02b3c28","execution_start":1733678235652,"execution_millis":1283,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"b49338407a19426e95e31e1b80f7f17d","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n\n# Membaca file CSV hasil sliding window\ntrain_windowed = pd.read_csv('train_windowed.csv')\ntest_windowed = pd.read_csv('test_windowed.csv')\n\n# Memisahkan fitur (Open_1, High_1, Low_1, ..., Open_4, High_4, Low_4) dan target (Close)\nX_train = train_windowed.drop(columns=['Close']).values\ny_train = train_windowed['Close'].values\nX_test = test_windowed.drop(columns=['Close']).values\ny_test = test_windowed['Close'].values\n\n# Membuat model Bagging dengan regresi linier sebagai estimator\nmodel = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=50, random_state=42)\n\n# Melatih model dengan data training\nmodel.fit(X_train, y_train)\n\n# Fungsi untuk prediksi multi-step\ndef multi_step_prediction(model, X_input, n_steps=3):\n    predictions = []\n    input_seq = X_input.copy()\n    for _ in range(n_steps):\n        # Prediksi satu langkah ke depan\n        pred = model.predict(input_seq.reshape(1, -1))\n        predictions.append(pred[0])\n        \n        # Update input untuk langkah berikutnya dengan menambahkan prediksi yang baru\n        input_seq = np.roll(input_seq, -3)  # Geser input untuk memasukkan nilai prediksi\n        input_seq[-3:] = pred  # Set nilai prediksi pada posisi terakhir input\n        \n    return predictions\n\n# Menyimpan hasil prediksi multi-step\nmulti_step_preds = []\n\nfor i in range(len(X_test)):\n    # Ambil fitur dari data testing dan lakukan prediksi multi-step\n    X_input = X_test[i]\n    preds = multi_step_prediction(model, X_input, n_steps=3)\n    multi_step_preds.append(preds)\n\n# Membuat DataFrame untuk hasil prediksi multi-step\nmulti_step_preds_df = pd.DataFrame(multi_step_preds, columns=['Predicted_1', 'Predicted_2', 'Predicted_3'])\n\n# Menampilkan hasil prediksi multi-step\nprint(\"Predictions for the next 3 days (multi-step prediction):\")\nprint(multi_step_preds_df)\n\n# Menghitung MSE, MAE, dan MAPE untuk prediksi multi-step\nmse = mean_squared_error(y_test[:len(multi_step_preds_df)], multi_step_preds_df['Predicted_1'])\nmae = mean_absolute_error(y_test[:len(multi_step_preds_df)], multi_step_preds_df['Predicted_1'])\nmape = mean_absolute_percentage_error(y_test[:len(multi_step_preds_df)], multi_step_preds_df['Predicted_1'])\n\n# Menampilkan hasil evaluasi\nprint(f'\\nEvaluation Metrics for 1st Step Prediction:')\nprint(f'Mean Squared Error: {mse}')\nprint(f'Mean Absolute Error: {mae}')\nprint(f'Mean Absolute Percentage Error: {mape}')\n","block_group":"23942400db3a4114b05e14bded838863","execution_count":6,"outputs":[{"name":"stdout","text":"Predictions for the next 3 days (multi-step prediction):\n     Predicted_1  Predicted_2  Predicted_3\n0       0.440686     0.445246     0.450104\n1       0.440574     0.445263     0.448505\n2       0.430145     0.433117     0.436669\n3       0.781067     0.788038     0.794262\n4       0.973884     0.981776     0.991400\n..           ...          ...          ...\n133     0.675926     0.681084     0.688312\n134     0.845706     0.854524     0.860580\n135     0.829224     0.835004     0.842829\n136     0.462247     0.466623     0.470255\n137     0.971338     0.979447     0.987757\n\n[138 rows x 3 columns]\n\nEvaluation Metrics for 1st Step Prediction:\nMean Squared Error: 0.00013946980980126145\nMean Absolute Error: 0.008859020561095825\nMean Absolute Percentage Error: 0.02622487381022546\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/5f230904-ca7c-4a35-8677-7de5ec2cab4b","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2a126699d4004c1989e63dad160ff5bb","deepnote_cell_type":"text-cell-p"},"source":"melakukan single step untuk data inputan baru","block_group":"093e0bdb07a042fcba759c25af5cca73"},{"cell_type":"code","metadata":{"source_hash":"3c7a2c65","execution_start":1733678840572,"execution_millis":311,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"a2bcb17b0d57432fa7e3f7427f214983","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\n\n# Membaca file CSV hasil sliding window\ntrain_windowed = pd.read_csv('train_windowed.csv')\ntest_windowed = pd.read_csv('test_windowed.csv')\n\n# Memisahkan fitur (Open_1, High_1, Low_1, ..., Open_4, High_4, Low_4) dan target (Close)\nX_train = train_windowed.drop(columns=['Close']).values\ny_train = train_windowed['Close'].values\nX_test = test_windowed.drop(columns=['Close']).values\ny_test = test_windowed['Close'].values\n\n# Membuat model Bagging dengan regresi linier sebagai estimator\nmodel = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=50, random_state=42)\n\n# Melatih model dengan data training\nmodel.fit(X_train, y_train)\n\n# Inputan baru yang diberikan\nnew_data = np.array([0.84929078, 0.84375, 0.839857651, 0.84929078, 0.826388889, 0.830960854,\n                     0.485815603, 0.470486111, 0.466192171, 0.964539007, 0.947916667, 0.973309609])\n\n# Melakukan prediksi untuk data baru\nnew_data_pred = model.predict(new_data.reshape(1, -1))\n\n# Menampilkan hasil prediksi\nprint(f\"Prediksi nilai Close untuk data baru: {new_data_pred[0]}\")\n","block_group":"84f63e7cc6b9458b88cc591d7909ef15","execution_count":9,"outputs":[{"name":"stdout","text":"Prediksi nilai Close untuk data baru: 0.9713381907064763\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e6d31f51-ab11-453d-abbf-8cb4e0044a01","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1f2eddd881e544d4b132f101c2760122","deepnote_cell_type":"text-cell-p"},"source":"melakukan multi step untuk data inputan baru","block_group":"5732ba131ff1429a81dffb7b2eb896be"},{"cell_type":"code","metadata":{"source_hash":"701ac46","execution_start":1733680904528,"execution_millis":550,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"f343ce4a663b4a308116f7e17eb0eaea","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\nfrom math import sqrt\n\n# Membaca file CSV hasil sliding window\ntrain_windowed = pd.read_csv('train_windowed.csv')\ntest_windowed = pd.read_csv('test_windowed.csv')\n\n# Memisahkan fitur (Open_1, High_1, Low_1, ..., Open_4, High_4, Low_4) dan target (Close)\nX_train = train_windowed.drop(columns=['Close']).values\ny_train = train_windowed['Close'].values\nX_test = test_windowed.drop(columns=['Close']).values\ny_test = test_windowed['Close'].values\n\n# Membuat model Bagging dengan regresi linier sebagai estimator\nmodel = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=50, random_state=42)\n\n# Melatih model dengan data training\nmodel.fit(X_train, y_train)\n\n# Prediksi pada data uji\ny_pred_test = model.predict(X_test)\n\n# Menghitung MAPE (Mean Absolute Percentage Error)\nmape = mean_absolute_percentage_error(y_test, y_pred_test)\n\n# Menghitung RMSE (Root Mean Squared Error)\nrmse = sqrt(mean_squared_error(y_test, y_pred_test))\n\n# Menampilkan MAPE dan RMSE\nprint(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\n\n# Inputan baru yang diberikan\nnew_data = np.array([0.84929078, 0.84375, 0.839857651, 0.84929078, 0.826388889, 0.830960854,\n                     0.485815603, 0.470486111, 0.466192171, 0.964539007, 0.947916667, 0.973309609])\n\n# Prediksi multi-step untuk 3 hari ke depan\nsteps = 3\npredictions = []\n\n# Iteratif untuk prediksi 3 langkah ke depan\ncurrent_input = new_data.reshape(1, -1)\nfor _ in range(steps):\n    prediction = model.predict(current_input)\n    predictions.append(prediction[0])\n    \n    # Update input untuk prediksi berikutnya\n    # Misalnya, kita ingin menambahkan prediksi hari ini ke fitur untuk prediksi hari berikutnya\n    current_input = np.roll(current_input, shift=-1, axis=1)\n    current_input[0, -1] = prediction\n\n# Menampilkan hasil prediksi multi-step\nprint(f\"Prediksi nilai Close untuk 3 hari ke depan: {predictions}\")\n","block_group":"eaec9162c4c1421daa51191ba4cea984","execution_count":24,"outputs":[{"name":"stdout","text":"Mean Absolute Percentage Error (MAPE): 0.026224873810225452\nRoot Mean Squared Error (RMSE): 0.011809733688837419\nPrediksi nilai Close untuk 3 hari ke depan: [0.9713381907064763, 0.9683982271117674, 0.9699121768732992]\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/28a1a415-0bb8-4307-87cd-325eee733f55","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"220a5668","execution_start":1733681179712,"execution_millis":192,"execution_context_id":"3449acd9-ca87-448d-bcc4-46d46ecbc4f6","cell_id":"54b378fa14614fb3bf63c8e6c68a1aff","deepnote_cell_type":"code"},"source":"import numpy as np\nimport joblib\nfrom sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\nfrom math import sqrt\nimport pandas as pd\n\n# Memuat model yang disimpan\nmodel = joblib.load('bagging_model_p3.joblib')\n\n# Inputan baru yang diberikan\nnew_data = np.array([0.556737589, 0.539930556, 0.519572954, 0.867021277, 0.852430556, 0.87544484,\n                     0.69858156, 0.670138889, 0.6886121, 0.84929078, 0.84375, 0.839857651])\n\n# Prediksi multi-step untuk 3 hari ke depan\nsteps = 3\npredictions = []\n\n# Iteratif untuk prediksi 3 langkah ke depan\ncurrent_input = new_data.reshape(1, -1)\nfor _ in range(steps):\n    prediction = model.predict(current_input)\n    predictions.append(prediction[0])\n    \n    # Update input untuk prediksi berikutnya\n    current_input = np.roll(current_input, shift=-1, axis=1)\n    current_input[0, -1] = prediction\n\n# Menampilkan hasil prediksi multi-step sebelum unnormalisasi\nprint(f\"Prediksi nilai Close untuk 3 hari ke depan (sebelum unnormalisasi): {predictions}\")\n\n# Unnormalize prediksi (min = 486, max = 1050)\nmin_value = 486\nmax_value = 1050\n\n# Unnormalize dan pastikan hasilnya adalah bilangan bulat\nunnormalized_predictions = [int(round((pred * (max_value - min_value)) + min_value)) for pred in predictions]\n\n# Menampilkan hasil unnormalisasi\nprint(f\"Prediksi nilai Close untuk 3 hari ke depan (setelah unnormalisasi, bilangan bulat): {unnormalized_predictions}\")\n\n# Untuk MAPE dan RMSE, prediksi pada data uji\n# Memuat data uji\ntest_windowed = pd.read_csv('test_windowed.csv')\nX_test = test_windowed.drop(columns=['Close']).values\ny_test = test_windowed['Close'].values\n\n# Prediksi pada data uji\ny_pred_test = model.predict(X_test)\n\n# Unnormalize prediksi pada data uji\nunnormalized_y_pred_test = [int(round((pred * (max_value - min_value)) + min_value)) for pred in y_pred_test]\n\n# Menghitung MAPE (Mean Absolute Percentage Error) sebelum unnormalisasi\nmape = mean_absolute_percentage_error(y_test, y_pred_test)\n\n# Menghitung RMSE (Root Mean Squared Error) sebelum unnormalisasi\nrmse = sqrt(mean_squared_error(y_test, y_pred_test))\n\n# Menampilkan MAPE dan RMSE pada data yang telah di unnormalisasi\nprint(f\"Mean Absolute Percentage Error (MAPE) setelah unnormalisasi: {mape}\")\nprint(f\"Root Mean Squared Error (RMSE) setelah unnormalisasi: {rmse}\")\n","block_group":"4909b48e03e64bbb911cd99a3324729f","execution_count":27,"outputs":[{"name":"stdout","text":"Prediksi nilai Close untuk 3 hari ke depan (sebelum unnormalisasi): [0.8457057750515322, 0.8453227690374149, 0.8784322227134386]\nPrediksi nilai Close untuk 3 hari ke depan (setelah unnormalisasi, bilangan bulat): [963, 963, 981]\nMean Absolute Percentage Error (MAPE) setelah unnormalisasi: 0.026224873810225452\nRoot Mean Squared Error (RMSE) setelah unnormalisasi: 0.011809733688837419\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/0b9ff53a-1a0d-4119-952a-c97a8115927f","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"fd5ecfd5708c4fbebd393d73c313f81a","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"f2b4bb0c4d30410091d3d9d5de585969"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c164e15a86b546409310e8c2aba317c6","deepnote_cell_type":"text-cell-h3"},"source":"### 4.2 LSTM","block_group":"1258520457ba49d99105547c5161aa95"},{"cell_type":"code","metadata":{"source_hash":"c5d53ecf","execution_start":1733669247616,"execution_millis":116385,"execution_context_id":"e49ef00b-4ba6-4faa-abe7-5d868af80b66","cell_id":"17c806b2e8624efc8eb1d4afa6f716fc","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n\n# Membaca file CSV data training dan testing\ntrain_data = pd.read_csv('train_data3.csv')\ntest_data = pd.read_csv('test_data3.csv')\n\n# Memisahkan fitur (Open, High, Low) dan target (Close) dari data training\nX_train = train_data[['Open', 'High', 'Low']].values\ny_train = train_data['Close'].values\n\n# Memisahkan fitur (Open, High, Low) dan target (Close) dari data testing\nX_test = test_data[['Open', 'High', 'Low']].values\ny_test = test_data['Close'].values\n\n# Fungsi untuk membuat dataset multi-step\ndef create_dataset(X, y, look_back=1, forecast_steps=3):\n    Xs, ys = [], []\n    for i in range(len(X) - look_back - forecast_steps + 1):\n        Xs.append(X[i:(i + look_back), :])  # Input: data sebelumnya\n        ys.append(y[(i + look_back):(i + look_back + forecast_steps)])  # Output: 3 hari ke depan\n    return np.array(Xs), np.array(ys)\n\nlook_back = 5  # Menggunakan 5 hari terakhir sebagai input\nforecast_steps = 3  # Memprediksi 3 hari ke depan\n\n# Membuat dataset untuk training dan testing\nX_train_multi, y_train_multi = create_dataset(X_train, y_train, look_back, forecast_steps)\nX_test_multi, y_test_multi = create_dataset(X_test, y_test, look_back, forecast_steps)\n\n# Membuat model LSTM\nmodel = Sequential()\nmodel.add(LSTM(units=50, return_sequences=False, input_shape=(X_train_multi.shape[1], X_train_multi.shape[2])))\nmodel.add(Dense(units=forecast_steps))  # Output untuk 3 hari ke depan\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Melatih model\nmodel.fit(X_train_multi, y_train_multi, epochs=100, batch_size=32, verbose=1)\n\n# Melakukan prediksi\npredictions = model.predict(X_test_multi)\n\n# Menghitung metrik evaluasi\nmae = mean_absolute_error(y_test_multi, predictions)\nrmse = np.sqrt(mean_squared_error(y_test_multi, predictions))\nmape = mean_absolute_percentage_error(y_test_multi, predictions)\n\n# Menampilkan hasil evaluasi\nprint(f\"MAE: {mae}\")\nprint(f\"RMSE: {rmse}\")\nprint(f\"MAPE: {mape * 100:.2f}%\")\n\n# Menyimpan hasil prediksi ke dalam DataFrame untuk output lengkap\nresults = pd.DataFrame({\n    'Actual Day 1': y_test_multi[:, 0],\n    'Predicted Day 1': predictions[:, 0],\n    'Actual Day 2': y_test_multi[:, 1],\n    'Predicted Day 2': predictions[:, 1],\n    'Actual Day 3': y_test_multi[:, 2],\n    'Predicted Day 3': predictions[:, 2]\n})\n\nprint(results)\n\n# Prediksi untuk Data Baru (Single-Step Multi-Step 3 Hari Ke Depan)\nnew_data = np.array([[0.971986, 0.661458, 0.688612]])  # Input baru: Open, High, Low\n\n# Memastikan data baru memiliki bentuk yang sesuai (1, look_back, 3)\n# Misalnya, kita perlu menambah langkah waktu sebelumnya untuk prediksi multi-step.\n# Di sini, kami asumsikan kita menggunakan data 5 hari terakhir.\n# Untuk keperluan ini, Anda harus menyediakan 5 data langkah sebelumnya untuk membuat prediksi.\n# Contoh data multi-step yang sesuai dengan look_back=5, pastikan data mencakup 5 hari sebelumnya.\nnew_data_multi = np.tile(new_data, (look_back, 1))  # Duplikasi data menjadi 5 langkah waktu\nnew_data_multi = new_data_multi.reshape((1, look_back, new_data.shape[1]))\n\n# Melakukan prediksi untuk data baru (multi-step)\nnew_predictions = model.predict(new_data_multi)\n\nprint(\"Prediksi untuk 3 hari ke depan:\", new_predictions)\n# Menghitung metrik evaluasi\nmae = mean_absolute_error(y_test_multi, predictions)\nrmse = np.sqrt(mean_squared_error(y_test_multi, predictions))\n\n# Menampilkan hasil evaluasi\nprint(f\"MAE: {mae}\")\nprint(f\"RMSE: {rmse}\")\n","block_group":"f05b34c551a44fdc897582fbee099c38","execution_count":2,"outputs":[{"name":"stderr","text":"2024-12-08 14:47:27.575504: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-12-08 14:47:27.695383: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2024-12-08 14:47:27.700372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-12-08 14:47:27.700420: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-12-08 14:47:27.724952: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-12-08 14:47:28.382473: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-12-08 14:47:28.382615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-12-08 14:47:28.382643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2024-12-08 14:47:29.382745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2024-12-08 14:47:29.383084: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2024-12-08 14:47:29.383128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-d71500c2-b449-45af-bb9d-9851cba6cfbc): /proc/driver/nvidia/version does not exist\n2024-12-08 14:47:29.383490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\nEpoch 1/100\n16/16 [==============================] - 3s 73ms/step - loss: 0.1050\nEpoch 2/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0649\nEpoch 3/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0639\nEpoch 4/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0637\nEpoch 5/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0632\nEpoch 6/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0629\nEpoch 7/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0622\nEpoch 8/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0624\nEpoch 9/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0620\nEpoch 10/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0623\nEpoch 11/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0615\nEpoch 12/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0614\nEpoch 13/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0622\nEpoch 14/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0622\nEpoch 15/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0612\nEpoch 16/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0612\nEpoch 17/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0609\nEpoch 18/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0608\nEpoch 19/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0608\nEpoch 20/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0606\nEpoch 21/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 22/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0609\nEpoch 23/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0610\nEpoch 24/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0615\nEpoch 25/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0612\nEpoch 26/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0609\nEpoch 27/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0611\nEpoch 28/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0606\nEpoch 29/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0615\nEpoch 30/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0608\nEpoch 31/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0613\nEpoch 32/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0610\nEpoch 33/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 34/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 35/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0606\nEpoch 36/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0612\nEpoch 37/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0608\nEpoch 38/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0604\nEpoch 39/100\n16/16 [==============================] - 1s 71ms/step - loss: 0.0606\nEpoch 40/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0608\nEpoch 41/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0605\nEpoch 42/100\n16/16 [==============================] - 1s 65ms/step - loss: 0.0610\nEpoch 43/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 44/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0606\nEpoch 45/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0605\nEpoch 46/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0610\nEpoch 47/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0605\nEpoch 48/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0607\nEpoch 49/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0603\nEpoch 50/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0604\nEpoch 51/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 52/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0608\nEpoch 53/100\n16/16 [==============================] - 1s 74ms/step - loss: 0.0604\nEpoch 54/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0607\nEpoch 55/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0605\nEpoch 56/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0605\nEpoch 57/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0610\nEpoch 58/100\n16/16 [==============================] - 1s 74ms/step - loss: 0.0608\nEpoch 59/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0606\nEpoch 60/100\n16/16 [==============================] - 1s 57ms/step - loss: 0.0607\nEpoch 61/100\n16/16 [==============================] - 1s 71ms/step - loss: 0.0605\nEpoch 62/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0604\nEpoch 63/100\n16/16 [==============================] - 1s 74ms/step - loss: 0.0608\nEpoch 64/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0605\nEpoch 65/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0605\nEpoch 66/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0604\nEpoch 67/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0604\nEpoch 68/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0607\nEpoch 69/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0605\nEpoch 70/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 71/100\n16/16 [==============================] - 1s 66ms/step - loss: 0.0606\nEpoch 72/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0609\nEpoch 73/100\n16/16 [==============================] - 1s 60ms/step - loss: 0.0606\nEpoch 74/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0606\nEpoch 75/100\n16/16 [==============================] - 1s 60ms/step - loss: 0.0605\nEpoch 76/100\n16/16 [==============================] - 1s 56ms/step - loss: 0.0608\nEpoch 77/100\n16/16 [==============================] - 1s 61ms/step - loss: 0.0609\nEpoch 78/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0604\nEpoch 79/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0603\nEpoch 80/100\n16/16 [==============================] - 1s 69ms/step - loss: 0.0605\nEpoch 81/100\n16/16 [==============================] - 1s 65ms/step - loss: 0.0607\nEpoch 82/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0606\nEpoch 83/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0607\nEpoch 84/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0604\nEpoch 85/100\n16/16 [==============================] - 1s 68ms/step - loss: 0.0604\nEpoch 86/100\n16/16 [==============================] - 1s 72ms/step - loss: 0.0606\nEpoch 87/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0604\nEpoch 88/100\n16/16 [==============================] - 1s 73ms/step - loss: 0.0604\nEpoch 89/100\n16/16 [==============================] - 1s 66ms/step - loss: 0.0605\nEpoch 90/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0603\nEpoch 91/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0614\nEpoch 92/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0605\nEpoch 93/100\n16/16 [==============================] - 1s 62ms/step - loss: 0.0604\nEpoch 94/100\n16/16 [==============================] - 1s 62ms/step - loss: 0.0609\nEpoch 95/100\n16/16 [==============================] - 1s 65ms/step - loss: 0.0612\nEpoch 96/100\n16/16 [==============================] - 1s 71ms/step - loss: 0.0607\nEpoch 97/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0604\nEpoch 98/100\n16/16 [==============================] - 1s 67ms/step - loss: 0.0608\nEpoch 99/100\n16/16 [==============================] - 1s 60ms/step - loss: 0.0611\nEpoch 100/100\n16/16 [==============================] - 1s 58ms/step - loss: 0.0606\n3/3 [==============================] - 0s 8ms/step\nMAE: 0.19294350130778537\nRMSE: 0.24263470203013618\nMAPE: 61.68%\n    Actual Day 1  Predicted Day 1  Actual Day 2  Predicted Day 2  \\\n0       0.414894         0.438450      0.406028         0.446893   \n1       0.406028         0.435734      0.459220         0.443280   \n2       0.459220         0.434868      0.326241         0.442353   \n3       0.326241         0.436092      0.299645         0.441917   \n4       0.299645         0.431421      0.787234         0.440047   \n..           ...              ...           ...              ...   \n75      0.875887         0.449544      0.671986         0.451472   \n76      0.671986         0.465619      0.858156         0.444390   \n77      0.858156         0.457073      0.831560         0.442544   \n78      0.831560         0.464386      0.476950         0.436415   \n79      0.476950         0.464129      0.973404         0.431670   \n\n    Actual Day 3  Predicted Day 3  \n0       0.459220         0.436538  \n1       0.326241         0.444788  \n2       0.299645         0.446073  \n3       0.787234         0.445019  \n4       0.432624         0.453496  \n..           ...              ...  \n75      0.858156         0.454249  \n76      0.831560         0.443304  \n77      0.476950         0.453011  \n78      0.973404         0.449318  \n79      0.157801         0.451547  \n\n[80 rows x 6 columns]\n1/1 [==============================] - 0s 26ms/step\nPrediksi untuk 3 hari ke depan: [[0.46997282 0.44431657 0.43401095]]\nMAE: 0.19294350130778537\nRMSE: 0.24263470203013618\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/ae8b22d8-1629-4245-8e2a-fe3fdf8e36dd","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d71500c2-b449-45af-bb9d-9851cba6cfbc' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-12-08T18:25:13.050Z"},"deepnote_notebook_id":"3a1c29e2c4d041a8aa645d6441811919"}}